# Grading Report: oai10

**Problem:** 10
**Grade:** 4/4 — Complete Solution

## Error Indicators

| Indicator | Value |
|---|---|
| Incorrect Logic | false |
| Hallucinated Results | false |
| Calculation Mistakes | false |
| Conceptual Misunderstanding | false |

## Achievement Indicators

| Indicator | Value |
|---|---|
| Problem Understanding | true |
| Correct End Result | true |
| Insight & Creativity | true |
| Practical Usefulness | true |

## Summary

The solution correctly derives a matrix-free PCG algorithm with a Kronecker-structured preconditioner, efficiently handling the sparse observations and RKHS constraints. The approach avoids O(N) computations as required. Reviewer critiques regarding the rigorous probabilistic justification of the preconditioner and the representer theorem are either minor expositional points or outside the scope of the specific prompt.

## Reviewer Issues

1. **[major]** (Correctness & Completeness) Preconditioner motivation (SS^T ≈ ρI): SS^T is a binary diagonal matrix (a projection), not ρI. The approximation requires an expected-value argument under uniform random sampling that is never stated. Without this, the preconditioner has no formal justification.
2. **[major]** (Correctness & Completeness) Problem setup / representer theorem: The problem states mode k is infinite-dimensional in an RKHS, but the solution assumes without justification that the optimization reduces to a finite n×n system via A_k = KW. The representer theorem argument that justifies this reduction is missing entirely.
3. **[minor]** (Correctness & Completeness) Notation (⊙ overloading): The symbol ⊙ is used for both the Khatri-Rao product (Z = A_d ⊙ ··· ⊙ A_1) and the Hadamard (elementwise) product in equation (97). This dual usage is standard in tensor literature but creates ambiguity within a single document.
4. **[minor]** (Correctness & Completeness) SPD verification of operator A: The proof claims the operator is SPD and that CG applies, but does not verify positive definiteness. While straightforward (λ > 0 and K ≻ 0 suffice), the claim should be justified since it is a prerequisite for the entire method.
5. **[minor]** (Correctness & Completeness) Equation (98), vec-Kronecker identity: The derivation jumps from Σ s_ℓ(z_ℓ ⊗ Ke_{i_ℓ}) to vec(K Σ e_{i_ℓ} s_ℓ z_ℓ^T) without citing the identity vec(abc^T) = (c ⊗ a)b used here. At graduate rigor, this step should be explicit.
6. **[minor]** (Correctness & Completeness) Complexity of Z_Ω construction: The parenthetical claim that Z_Ω can be built in O(qr) 'if factor rows are accessed efficiently' is incorrect — the (d-1) factor is inherent in computing products over d-1 modes and cannot be removed by access patterns alone.
7. **[minor]** (Correctness & Completeness) PCG convergence analysis: The convergence section only states the generic CG convergence bound and a heuristic argument that eigenvalues cluster when the mask is uniform. No quantitative bound on κ(P^{-1}A) is given in terms of (n, r, q, ρ). The 'fast convergence' claim is empirical, not proven.
8. **[minor]** (Correctness & Completeness) Gram matrix identity (103): The Hadamard-product identity for the Gram matrix of a Khatri-Rao product is stated without proof or reference. While well-known, at graduate rigor a one-line verification or citation strengthens the exposition.
9. **[major]** (Clarity & Rigor) PCG formulation (system (95), SPD claim paragraph): CG/PCG requires an SPD operator, but the assumptions ensuring SPD are not fully stated (notably lambda > 0). The text discusses K being PD or nuggeted, but does not explicitly enforce lambda > 0 in the theorem-level statement.
10. **[major]** (Clarity & Rigor) A Kronecker preconditioner from mean masking (Eq. 102): The replacement SS^T ≈ rho I is introduced as a practical step but without a precise sampling model; as written it can read like an identity rather than a model-based approximation.
11. **[major]** (Clarity & Rigor) Why PCG converges quickly: The claim that SS^T is spectrally close to rho I and that eigenvalues cluster is asserted without quantitative conditions, proof sketch, or citation.
12. **[major]** (Clarity & Rigor) Eq. (104) and matrix-free matvec algorithm: Notation collisions reduce precision: r denotes both CP rank and residual vector; U denotes both eigenvectors of K and a temporary matrix U = KX.
13. **[minor]** (Clarity & Rigor) Observed-index notation and Eq. (100): The mapping from tensor multi-index to unfolding column index j_l is implicit, and duplicate observations are not discussed; this leaves scatter formulas slightly under-specified.
14. **[minor]** (Clarity & Rigor) Eqs. (97)–(99): z_l is used as both row and column in different places; transposes are inferable but not consistently explicit.
15. **[minor]** (Clarity & Rigor) Complexity section: Complexity statements rely on hidden assumptions (dense K matvec at O(n^2 r), cheap row access for all fixed factors), which are not stated explicitly.
16. **[minor]** (Reference Validity) Section 'A Kronecker preconditioner from mean masking': The text justifies the preconditioner by stating that $S S^T \approx \rho I$ is a 'common and effective approximation' when the mask is uniform. This appeals to external results regarding the spectral properties of random sampling operators (concentration of measure) without citation or proof.
17. **[minor]** (Reference Validity) Section 'Why PCG converges quickly': The text invokes 'standard PCG theory' to provide a specific convergence bound inequality. While the result is correct, graduate-level rigor requires citing a specific source when invoking a named theorem or bound.
